{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Problem Statement\n",
    "1) Target variable is Catgeorical in nature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix\n",
    "\n",
    "1) It is square matrix, consisting of 4 terms - TP,FN,FP and TN<br>\n",
    "2) Is the number of categories in target varaibles is n, then shape of the confusion matrix is n*n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terminologies\n",
    "\n",
    "1) <b>TP (True Positive)</b><br>\n",
    "Actual value is positive, ML or DL model also predicted a positive value.\n",
    "\n",
    "2) <b>FP (False Positive)</b><br>\n",
    "Actual value is negative, ML or DL model predicted a positive value.\n",
    "\n",
    "3) <b>FN (False Negative)</b><br>\n",
    "Actual value is positive, ML or DL model predicted a negative value.\n",
    "\n",
    "4) <b>TN (True Negative)</b><br>\n",
    "Actual value is negative, ML or DL model also predicted a negative value.\n",
    "\n",
    "\n",
    "<br>Note\n",
    "1) Sum of all actual positive values = TP + FN<br>\n",
    "2) Sum of all actual negative values = FP + TN<br>\n",
    "3) Sum of all positively predicted values = TP + FP<br>\n",
    "4) Sum of all negatively predicted values = FN + TN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Metrics\n",
    "\n",
    "1) <b>Precision = TP/(TP+FP), TN/(TN+FN)</b><br>\n",
    "From sum of all positively predicted cases, how many are actually positive.<br>\n",
    "From sum of all negatively predicted cases, how many are actually negative.\n",
    "\n",
    "2) <b>Recall = TP/(TP+FN), TN/(TN+FP)</b><br>\n",
    "From sum of all actually positive cases, how many has the model predicted as positive<br>\n",
    "From sum of all actually negative cases, how many has the model predicted as negative<br>\n",
    "\n",
    "3) <b>F1-Score = 2 * Precision * Recall /(Precision + Recall)</b><br>\n",
    "It is the Harmonic mean between Precision and Recall<br>\n",
    "\n",
    "4) <b>Accuracy = (TP +TN)/(TP+FN+TN+FP)</b><br>\n",
    "Overall, how good is the model perfroming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = ['Age','BMI','BGL','Body_wt','Gender','SkinThickness']\n",
    "# y = Diabetic(0) or non-diabetic(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "# 0 - Positive(True), 1 - Negative(False)\n",
    "y_true = [1,0,1,1,0,0,1,0,0,0,1,0,1,0,0,1,1,1,0,1,0,1]\n",
    "y_pred = [0,1,0,1,0,1,1,1,0,0,0,1,1,0,1,1,1,0,1,0,1,0]\n",
    "print(len(y_true))\n",
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 7]\n",
      " [6 5]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true,y_pred)\n",
    "print(cm)\n",
    "# Actual value=0, predicted value=0 => TP = 4\n",
    "# Actual value=0, predicted value=1 => FN = 7\n",
    "# Actual value=1, predicted value=0 => FP = 6\n",
    "# Actual value=1, predicted value=1 => TN = 5\n",
    "# [TP FN]\n",
    "# [FP TN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.36      0.38        11\n",
      "           1       0.42      0.45      0.43        11\n",
      "\n",
      "    accuracy                           0.41        22\n",
      "   macro avg       0.41      0.41      0.41        22\n",
      "weighted avg       0.41      0.41      0.41        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 7]\n",
      " [6 5]]\n"
     ]
    }
   ],
   "source": [
    "# Precision = TP/(TP+FP), TN/(TN+FN)\n",
    "# Recall = TP/(TP+FN), TN/(TN+FP)\n",
    "# F1-Score = 2 * Precision * Recall /(Precision + Recall)\n",
    "# Acc = (TP+TN)/(TP+TN+FP+FN)\n",
    "# [TP=4 FN=7]\n",
    "# [FP=6 TN=5]\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.4166666666666667\n",
      "0.36363636363636365 0.45454545454545453\n"
     ]
    }
   ],
   "source": [
    "pre0 = 4/(4+6)\n",
    "pre1 = 5/(5+7)\n",
    "rec0 = 4/(4+7)\n",
    "rec1 = 5/(5+6)\n",
    "print(pre0,pre1)\n",
    "print(rec0,rec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.380952380952381 0.43478260869565216\n"
     ]
    }
   ],
   "source": [
    "f1s0 = 2*pre0*rec0/(pre0+rec0)\n",
    "f1s1 = 2*pre1*rec1/(pre1+rec1)\n",
    "print(f1s0,f1s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 7],\n",
       "       [6, 5]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4090909090909091\n"
     ]
    }
   ],
   "source": [
    "acc = (4+5)/(4+6+7+5)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
